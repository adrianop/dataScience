{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536e4428",
   "metadata": {},
   "source": [
    "# Tratamento e criação dataset de acidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c7bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913375, 38)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho raiz onde estão os diretórios com CSVs\n",
    "caminho_raiz = 'dados/acidentes'  # exemplo: 'C:/meus_dados/csvs'\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "lista_df = []\n",
    "\n",
    "# Percorre todos os diretórios e subdiretórios\n",
    "for root, dirs, files in os.walk(caminho_raiz):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            caminho_completo = os.path.join(root, file)\n",
    "            try:\n",
    "                df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
    "                df['origem_arquivo'] = file  # opcional: identifica a origem\n",
    "                lista_df.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao ler {caminho_completo}: {e}\")\n",
    "\n",
    "# Junta todos os DataFrames\n",
    "df_unificado = pd.concat(lista_df, ignore_index=True)\n",
    "\n",
    "# Exibe ou salva\n",
    "print(df_unificado.shape)\n",
    "df_unificado.to_csv('dados/acidentes/acidentes_agrupado.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db0a8f",
   "metadata": {},
   "source": [
    "# Tratamento e criação dataset de infrações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0934fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
      "C:\\Users\\pertile\\AppData\\Local\\Temp\\1\\ipykernel_2636\\1495592176.py:16: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22535242, 26)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho raiz onde estão os diretórios com CSVs\n",
    "caminho_raiz = 'dados/infracoes'  # exemplo: 'C:/meus_dados/csvs'\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "lista_df = []\n",
    "\n",
    "# Percorre todos os diretórios e subdiretórios\n",
    "for root, dirs, files in os.walk(caminho_raiz):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            caminho_completo = os.path.join(root, file)\n",
    "            try:\n",
    "                df = pd.read_csv(caminho_completo, sep=';', encoding='latin1')  # ajuste sep/encoding se necessário\n",
    "                df['origem_arquivo'] = file  # opcional: identifica a origem\n",
    "                lista_df.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao ler {caminho_completo}: {e}\")\n",
    "\n",
    "# Junta todos os DataFrames\n",
    "df_unificado = pd.concat(lista_df, ignore_index=True)\n",
    "\n",
    "# Exibe ou salva\n",
    "print(df_unificado.shape)\n",
    "df_unificado.to_csv('dados/infracoes/infracoes_agrupado.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33da25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Resumo da Análise:\n",
      "❌ Foram encontradas 5 estruturas de colunas diferentes.\n",
      "\n",
      "dataset_unificado_por_ocorrencia.csv: ['id;data_inversa;dia_semana;horario;uf;br;km;municipio;causa_acidente;tipo_acidente;classificacao_acidente;fase_dia;sentido_via;condicao_metereologica;tipo_pista;tracado_via;uso_solo;pessoas;mortos;feridos_leves;feridos_graves;ilesos;ignorados;feridos;veiculos']\n",
      "datatran2007.csv: ['id;data_inversa;dia_semana;horario;uf;br;km;municipio;causa_acidente;tipo_acidente;classificacao_acidente;fase_dia;sentido_via;condicao_metereologica;tipo_pista;tracado_via;uso_solo;ano;pessoas;mortos;feridos_leves;feridos_graves;ilesos;ignorados;feridos;veiculos']\n",
      "datatran2008.csv: ['id;data_inversa;dia_semana;horario;uf;br;km;municipio;causa_acidente;tipo_acidente;classificacao_acidente;fase_dia;sentido_via;condicao_metereologica;tipo_pista;tracado_via;uso_solo;ano;pessoas;mortos;feridos_leves;feridos_graves;ilesos;ignorados;feridos;veiculos']\n",
      "datatran2009.csv: ['id;data_inversa;dia_semana;horario;uf;br;km;municipio;causa_acidente;tipo_acidente;classificacao_acidente;fase_dia;sentido_via;condicao_metereologica;tipo_pista;tracado_via;uso_solo;ano;pessoas;mortos;feridos_leves;feridos_graves;ilesos;ignorados;feridos;veiculos']\n",
      "datatran2010.csv: ['id;data_inversa;dia_semana;horario;uf;br;km;municipio;causa_acidente;tipo_acidente;classificacao_acidente;fase_dia;sentido_via;condicao_metereologica;tipo_pista;tracado_via;uso_solo;ano;pessoas;mortos;feridos_leves;feridos_graves;ilesos;ignorados;feridos;veiculos']\n",
      "datatran2011.csv: ['id;data_inversa;dia_semana;horario;uf;br;km;municipio;causa_acidente;tipo_acidente;classificacao_acidente;fase_dia;sentido_via;condicao_metereologica;tipo_pista;tracado_via;uso_solo;ano;pessoas;mortos;feridos_leves;feridos_graves;ilesos;ignorados;feridos;veiculos']\n",
      "datatran2012.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"ano\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\"']\n",
      "datatran2013.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"ano\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\"']\n",
      "datatran2014.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"ano\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\"']\n",
      "datatran2015.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"ano\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\"']\n",
      "datatran2016.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\"']\n",
      "datatran2017.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2018.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2019.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2020.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2021.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2022.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2023.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2024.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n",
      "datatran2025.csv: ['id;\"data_inversa\";\"dia_semana\";\"horario\";\"uf\";\"br\";\"km\";\"municipio\";\"causa_acidente\";\"tipo_acidente\";\"classificacao_acidente\";\"fase_dia\";\"sentido_via\";\"condicao_metereologica\";\"tipo_pista\";\"tracado_via\";\"uso_solo\";\"pessoas\";\"mortos\";\"feridos_leves\";\"feridos_graves\";\"ilesos\";\"ignorados\";\"feridos\";\"veiculos\";\"latitude\";\"longitude\";\"regional\";\"delegacia\";\"uop\"']\n"
     ]
    }
   ],
   "source": [
    "### verificar se todos os arquivos dos acidentes por ocorrencia tem as mesmas colunas\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho da pasta com os CSVs\n",
    "pasta_csv = r'dados/acidentes/por ocorrencia'  # Substitua aqui\n",
    "\n",
    "# Lista para armazenar os nomes das colunas de cada arquivo\n",
    "\n",
    "colunas_arquivos = {}\n",
    "\n",
    "for arquivo in os.listdir(pasta_csv):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        caminho_arquivo = os.path.join(pasta_csv, arquivo)\n",
    "        try:\n",
    "            df = pd.read_csv(caminho_arquivo, nrows=0, encoding='latin1')  # <- encoding adicionado\n",
    "            colunas_arquivos[arquivo] = list(df.columns)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erro ao ler {arquivo}: {e}\")\n",
    "\n",
    "colunas_unicas = set(tuple(v) for v in colunas_arquivos.values())\n",
    "\n",
    "print(\"\\n📊 Resumo da Análise:\")\n",
    "if len(colunas_unicas) == 1:\n",
    "    print(\"✅ Todos os arquivos têm as mesmas colunas.\")\n",
    "else:\n",
    "    print(f\"❌ Foram encontradas {len(colunas_unicas)} estruturas de colunas diferentes.\\n\")\n",
    "    for arquivo, colunas in colunas_arquivos.items():\n",
    "        print(f\"{arquivo}: {colunas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1df5bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (15,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (14,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15440\\3279823696.py:20: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     primeira_linha \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m     18\u001b[0m     separador \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m primeira_linha \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 20\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(caminho_arquivo, sep\u001b[38;5;241m=\u001b[39mseparador, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m colunas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([c\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns])  \u001b[38;5;66;03m# Normaliza nomes\u001b[39;00m\n\u001b[0;32m     22\u001b[0m colunas_arquivos[arquivo] \u001b[38;5;241m=\u001b[39m colunas\n",
      "File \u001b[1;32mc:\\Users\\adria\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\adria\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\adria\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\adria\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:281\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho da pasta com os CSVs\n",
    "pasta_csv = r'dados/infracoes'  # ajuste aqui\n",
    "\n",
    "colunas_arquivos = {}\n",
    "arquivos_lidos = {}\n",
    "\n",
    "# Primeiro passo: ler e identificar colunas\n",
    "for arquivo in os.listdir(pasta_csv):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        caminho_arquivo = os.path.join(pasta_csv, arquivo)\n",
    "        try:\n",
    "            # Tenta identificar o separador correto\n",
    "            with open(caminho_arquivo, 'r', encoding='latin1') as f:\n",
    "                primeira_linha = f.readline()\n",
    "                separador = ';' if ';' in primeira_linha else ','\n",
    "\n",
    "            df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
    "            colunas = tuple([c.strip().replace('\"','').lower() for c in df.columns])  # Normaliza nomes\n",
    "            colunas_arquivos[arquivo] = colunas\n",
    "            arquivos_lidos[arquivo] = df\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erro ao ler {arquivo}: {e}\")\n",
    "\n",
    "# Agrupa arquivos com as mesmas colunas\n",
    "from collections import defaultdict\n",
    "grupos = defaultdict(list)\n",
    "\n",
    "for arquivo, colunas in colunas_arquivos.items():\n",
    "    grupos[colunas].append(arquivo)\n",
    "\n",
    "# Exibe os grupos encontrados\n",
    "print(\"\\n📊 Grupos encontrados:\")\n",
    "for i, (colunas, arquivos) in enumerate(grupos.items(), 1):\n",
    "    print(f\"\\nGrupo {i} (colunas: {len(colunas)}): {arquivos}\")\n",
    "    print(f\"Colunas: {colunas}\")\n",
    "\n",
    "# Junta o maior grupo (mais comum) em um único DataFrame\n",
    "grupo_principal = max(grupos.items(), key=lambda x: len(x[1]))[1]\n",
    "\n",
    "dfs_para_concatenar = [arquivos_lidos[arq] for arq in grupo_principal]\n",
    "df_final = pd.concat(dfs_para_concatenar, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✅ Arquivos unidos: {grupo_principal}\")\n",
    "print(f\"🔢 Total de registros: {len(df_final)}\")\n",
    "\n",
    "# Se quiser salvar:\n",
    "df_final.to_csv(os.path.join(pasta_csv, 'dataset_unificado.csv'), sep=';', index=False, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18637dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15416\\2361994543.py:24: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15416\\2361994543.py:24: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15416\\2361994543.py:24: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Arquivos usados (19): ['datatran2007.csv', 'datatran2008.csv', 'datatran2009.csv', 'datatran2010.csv', 'datatran2011.csv', 'datatran2012.csv', 'datatran2013.csv', 'datatran2014.csv', 'datatran2015.csv', 'datatran2016.csv', 'datatran2017.csv', 'datatran2018.csv', 'datatran2019.csv', 'datatran2020.csv', 'datatran2021.csv', 'datatran2022.csv', 'datatran2023.csv', 'datatran2024.csv', 'datatran2025.csv']\n",
      "❌ Arquivos pulados (0): []\n",
      "🔢 Total de registros no dataset final: 2150936\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho da pasta com os CSVs\n",
    "pasta_csv = r'dados/acidentes/por ocorrencia'  # ajuste aqui\n",
    "\n",
    "# Defina as colunas que você quer manter (padronizadas: minúsculas e sem espaços)\n",
    "colunas_alvo = ['id', 'data_inversa', 'dia_semana', 'horario', 'uf', 'br', 'km', 'municipio', 'causa_acidente', 'tipo_acidente', 'classificacao_acidente', 'fase_dia', 'sentido_via', 'condicao_metereologica', 'tipo_pista', 'tracado_via', 'uso_solo', 'pessoas', 'mortos', 'feridos_leves', 'feridos_graves', 'ilesos', 'ignorados', 'feridos', 'veiculos']\n",
    "\n",
    "dfs_validos = []\n",
    "arquivos_usados = []\n",
    "arquivos_pulados = []\n",
    "\n",
    "for arquivo in os.listdir(pasta_csv):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        caminho_arquivo = os.path.join(pasta_csv, arquivo)\n",
    "        try:\n",
    "            # Detecta separador\n",
    "            with open(caminho_arquivo, 'r', encoding='latin1') as f:\n",
    "                primeira_linha = f.readline()\n",
    "                separador = ';' if ';' in primeira_linha else ','\n",
    "\n",
    "            # Lê o CSV\n",
    "            df = pd.read_csv(caminho_arquivo, sep=separador, encoding='latin1')\n",
    "\n",
    "            # Padroniza colunas\n",
    "            df.columns = [col.strip().replace('\"','').lower() for col in df.columns]\n",
    "\n",
    "            # Verifica se todas as colunas alvo estão presentes\n",
    "            if all(col in df.columns for col in colunas_alvo):\n",
    "                df_filtrado = df[colunas_alvo]\n",
    "                dfs_validos.append(df_filtrado)\n",
    "                arquivos_usados.append(arquivo)\n",
    "            else:\n",
    "                arquivos_pulados.append(arquivo)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erro ao ler {arquivo}: {e}\")\n",
    "            arquivos_pulados.append(arquivo)\n",
    "\n",
    "# Concatena os DataFrames válidos\n",
    "df_final = pd.concat(dfs_validos, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✅ Arquivos usados ({len(arquivos_usados)}): {arquivos_usados}\")\n",
    "print(f\"❌ Arquivos pulados ({len(arquivos_pulados)}): {arquivos_pulados}\")\n",
    "print(f\"🔢 Total de registros no dataset final: {len(df_final)}\")\n",
    "\n",
    "# Salva resultado\n",
    "df_final.to_csv(os.path.join(pasta_csv, 'dataset_unificado.csv'), sep=';', index=False, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ea54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo: dados/infracoes\\abr.csv\n",
      "Lendo: dados/infracoes\\abr2015.csv\n",
      "Lendo: dados/infracoes\\abr2016.csv\n",
      "Lendo: dados/infracoes\\abr2017.csv\n",
      "Lendo: dados/infracoes\\ago.csv\n",
      "Lendo: dados/infracoes\\ago2015.csv\n",
      "Lendo: dados/infracoes\\ago2016.csv\n",
      "Lendo: dados/infracoes\\ago2017.csv\n",
      "Lendo: dados/infracoes\\dez.csv\n",
      "Lendo: dados/infracoes\\dez2015.csv\n",
      "Lendo: dados/infracoes\\dez2016.csv\n",
      "Lendo: dados/infracoes\\dez2017.csv\n",
      "Lendo: dados/infracoes\\fev.csv\n",
      "Lendo: dados/infracoes\\fev2015.csv\n",
      "Lendo: dados/infracoes\\fev2016.csv\n",
      "Lendo: dados/infracoes\\fev2017.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_01.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_02.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_03.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_04.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_05.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_06.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_07.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_08.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_09.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_10.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_11.csv\n",
      "Lendo: dados/infracoes\\infracoes_2019_12.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_01.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_02.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_03.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_04.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_05.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_06.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_07.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_08.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_09.csv\n",
      "Lendo: dados/infracoes\\infracoes_2020_10.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_01.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_02.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_03.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_04.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_05.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_06.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_07.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_08.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_09.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_10.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_11.csv\n",
      "Lendo: dados/infracoes\\infraçoes2021_12.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_01.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_02.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_03.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_04.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_05.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_06.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_07.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_08.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_09.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_10.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_11.csv\n",
      "Lendo: dados/infracoes\\infraçoes2022_12.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_01.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_02.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_03.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_04.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_05.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_06.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_07.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_08.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_09.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_10.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_11.csv\n",
      "Lendo: dados/infracoes\\infraçoes2023_12.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_01.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_02.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_03.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_04.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_05.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_07.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_08.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_09.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_10.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_11.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_12a.csv\n",
      "Lendo: dados/infracoes\\infraçoes2024_12b.csv\n",
      "Lendo: dados/infracoes\\infraçoes2025_01.csv\n",
      "Lendo: dados/infracoes\\infraçoes2025_02.csv\n",
      "Lendo: dados/infracoes\\infraçoes2025_03.csv\n",
      "Lendo: dados/infracoes\\infraçoes2025_04.csv\n",
      "Lendo: dados/infracoes\\infraçoes_2020_11.csv\n",
      "Lendo: dados/infracoes\\infraçoes_2020_12.csv\n",
      "Lendo: dados/infracoes\\jan.csv\n",
      "Lendo: dados/infracoes\\jan2015.csv\n",
      "Lendo: dados/infracoes\\jan2016.csv\n",
      "Lendo: dados/infracoes\\jan2017.csv\n",
      "Lendo: dados/infracoes\\jan_fev.csv\n",
      "Lendo: dados/infracoes\\jan_fev2007.csv\n",
      "Lendo: dados/infracoes\\jan_fev2008.csv\n",
      "Lendo: dados/infracoes\\jan_fev2009.csv\n",
      "Lendo: dados/infracoes\\jan_fev2010.csv\n",
      "Lendo: dados/infracoes\\jan_fev2011.csv\n",
      "Lendo: dados/infracoes\\jan_fev2012.csv\n",
      "Lendo: dados/infracoes\\jan_fev2013.csv\n",
      "Lendo: dados/infracoes\\jul.csv\n",
      "Lendo: dados/infracoes\\jul2015.csv\n",
      "Lendo: dados/infracoes\\jul2016.csv\n",
      "Lendo: dados/infracoes\\jul2017.csv\n",
      "Lendo: dados/infracoes\\jul_ago.csv\n",
      "Lendo: dados/infracoes\\jul_ago2007.csv\n",
      "Lendo: dados/infracoes\\jul_ago2008.csv\n",
      "Lendo: dados/infracoes\\jul_ago2009.csv\n",
      "Lendo: dados/infracoes\\jul_ago2010.csv\n",
      "Lendo: dados/infracoes\\jul_ago2011.csv\n",
      "Lendo: dados/infracoes\\jul_ago2012.csv\n",
      "Lendo: dados/infracoes\\jul_ago2013.csv\n",
      "Lendo: dados/infracoes\\jun.csv\n",
      "Lendo: dados/infracoes\\jun2015.csv\n",
      "Lendo: dados/infracoes\\jun2016.csv\n",
      "Lendo: dados/infracoes\\jun2017.csv\n",
      "Lendo: dados/infracoes\\mai.csv\n",
      "Lendo: dados/infracoes\\mai2015.csv\n",
      "Lendo: dados/infracoes\\mai2016.csv\n",
      "Lendo: dados/infracoes\\mai2017.csv\n",
      "Lendo: dados/infracoes\\mai_jun.csv\n",
      "Lendo: dados/infracoes\\mai_jun2007.csv\n",
      "Lendo: dados/infracoes\\mai_jun2008.csv\n",
      "Lendo: dados/infracoes\\mai_jun2009.csv\n",
      "Lendo: dados/infracoes\\mai_jun2010.csv\n",
      "Lendo: dados/infracoes\\mai_jun2011.csv\n",
      "Lendo: dados/infracoes\\mai_jun2012.csv\n",
      "Lendo: dados/infracoes\\mai_jun2013.csv\n",
      "Lendo: dados/infracoes\\mar.csv\n",
      "Lendo: dados/infracoes\\mar2015.csv\n",
      "Lendo: dados/infracoes\\mar2016.csv\n",
      "Lendo: dados/infracoes\\mar2017.csv\n",
      "Lendo: dados/infracoes\\mar_abr.csv\n",
      "Lendo: dados/infracoes\\mar_abr2007.csv\n",
      "Lendo: dados/infracoes\\mar_abr2008.csv\n",
      "Lendo: dados/infracoes\\mar_abr2009.csv\n",
      "Lendo: dados/infracoes\\mar_abr2010.csv\n",
      "Lendo: dados/infracoes\\mar_abr2011.csv\n",
      "Lendo: dados/infracoes\\mar_abr2012.csv\n",
      "Lendo: dados/infracoes\\mar_abr2013.csv\n",
      "Lendo: dados/infracoes\\nov.csv\n",
      "Lendo: dados/infracoes\\nov2015.csv\n",
      "Lendo: dados/infracoes\\nov2016.csv\n",
      "Lendo: dados/infracoes\\nov2017.csv\n",
      "Lendo: dados/infracoes\\nov_dez.csv\n",
      "Lendo: dados/infracoes\\nov_dez2007.csv\n",
      "Lendo: dados/infracoes\\nov_dez2008.csv\n",
      "Lendo: dados/infracoes\\nov_dez2009.csv\n",
      "Lendo: dados/infracoes\\nov_dez2010.csv\n",
      "Lendo: dados/infracoes\\nov_dez2011.csv\n",
      "Lendo: dados/infracoes\\nov_dez2012.csv\n",
      "Lendo: dados/infracoes\\nov_dez2013.csv\n",
      "Lendo: dados/infracoes\\out.csv\n",
      "Lendo: dados/infracoes\\out2015.csv\n",
      "Lendo: dados/infracoes\\out2016.csv\n",
      "Lendo: dados/infracoes\\out2017.csv\n",
      "Lendo: dados/infracoes\\set.csv\n",
      "Lendo: dados/infracoes\\set2015.csv\n",
      "Lendo: dados/infracoes\\set2016.csv\n",
      "Lendo: dados/infracoes\\set2017.csv\n",
      "Lendo: dados/infracoes\\set_out.csv\n",
      "Lendo: dados/infracoes\\set_out2007.csv\n",
      "Lendo: dados/infracoes\\set_out2008.csv\n",
      "Lendo: dados/infracoes\\set_out2009.csv\n",
      "Lendo: dados/infracoes\\set_out2010.csv\n",
      "Lendo: dados/infracoes\\set_out2011.csv\n",
      "Lendo: dados/infracoes\\set_out2012.csv\n",
      "Lendo: dados/infracoes\\set_out2013.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def standardize_column_name(col_name):\n",
    "    # Remove BOM (Byte Order Mark) if present\n",
    "    col_name = col_name.replace(\"\\ufeff\", \"\")\n",
    "    # Normalize unicode characters (e.g., remove accents)\n",
    "    col_name = unicodedata.normalize(\"NFKD\", col_name).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    # Convert to lowercase\n",
    "    col_name = col_name.lower()\n",
    "    # Replace spaces and hyphens with underscores\n",
    "    col_name = col_name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    # Remove any non-alphanumeric characters (except underscores)\n",
    "    col_name = \"\".join(char for char in col_name if char.isalnum() or char == \"_\")\n",
    "    return col_name\n",
    "\n",
    "# Caminho raiz onde estão os diretórios com CSVs\n",
    "caminho_raiz = 'dados/infracoes'  # exemplo: 'C:/meus_dados/csvs'\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "lista_df = []\n",
    "\n",
    "# Percorre todos os diretórios e subdiretórios\n",
    "for root, dirs, files in os.walk(caminho_raiz):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            caminho_completo = os.path.join(root, file)\n",
    "            print(f\"Tentando ler: {caminho_completo}\")\n",
    "            try:\n",
    "                # Tenta ler com sep=\\\";\\\", encoding=\\\\'latin1\\\\', e motor python para robustez\n",
    "                # on_bad_lines=\\\\'skip\\\\'' para pular linhas mal formatadas\n",
    "                try:\n",
    "                    df = pd.read_csv(caminho_completo, sep=';', encoding='latin1', engine='python', on_bad_lines='skip')\n",
    "                except Exception as e:\n",
    "                    print(f\"Falha com sep=\\\";\\\", latin1. Tentando utf-8: {e}\")\n",
    "                    df = pd.read_csv(caminho_completo, sep=';', encoding='utf-8', engine='python', on_bad_lines='skip')\n",
    "                \n",
    "                # Padroniza os nomes das colunas\n",
    "                df.columns = [standardize_column_name(col) for col in df.columns]\n",
    "\n",
    "                df['origem_arquivo'] = file  # opcional: identifica a origem\n",
    "                lista_df.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro crítico ao ler {caminho_completo}: {e}\")\n",
    "\n",
    "# Junta todos os DataFrames\n",
    "df_unificado = pd.concat(lista_df, ignore_index=True)\n",
    "\n",
    "# Exibe ou salva\n",
    "print(df_unificado.shape)\n",
    "df_unificado.to_csv('dados/infracoes/infracoes_agrupado.csv', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
